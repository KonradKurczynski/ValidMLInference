{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ValidMLInference: example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ValidMLInference import ols, ols_bca, ols_bcm, one_step\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsim    = 1000\n",
    "n       = 16000      # training size\n",
    "m       = 1000       # test size\n",
    "p       = 0.05       # P(X=1)\n",
    "kappa   = 1.0        # measurement‐error strength\n",
    "fpr     = kappa / sqrt(n)\n",
    "\n",
    "β0, β1       = 10.0, 1.0\n",
    "σ0, σ1       = 0.3, 0.5\n",
    "\n",
    "# Bayesian parameters for the false positive rate for BCA and BCM bias correction\n",
    "α = [0.0, 0.5, 0.5]\n",
    "β = [0.0, 2.0, 4.0]\n",
    "\n",
    "# pre­allocate storage: (sim × 9 methods × 2 coefficients)\n",
    "B = np.zeros((nsim, 9, 2))\n",
    "S = np.zeros((nsim, 9, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n, m, p, fpr, β0, β1, σ0, σ1):\n",
    "    \"\"\"\n",
    "    Generates simulated data.\n",
    "\n",
    "    Parameters:\n",
    "      n, m: Python integers (number of training and test samples)\n",
    "      p, p1: floats\n",
    "      beta0, beta1: floats\n",
    "\n",
    "    Returns:\n",
    "      A tuple: ((train_Y, train_X), (test_Y, test_Xhat, test_X))\n",
    "      where train_X and test_Xhat include a constant term as the second column.\n",
    "    \"\"\"\n",
    "    N = n + m\n",
    "    X    = np.zeros(N)\n",
    "    Xhat = np.zeros(N)\n",
    "    u    = np.random.rand(N)\n",
    "\n",
    "    for j in range(N):\n",
    "        if   u[j] <= fpr:\n",
    "            X[j] = 1.0\n",
    "        elif u[j] <= 2*fpr:\n",
    "            Xhat[j] = 1.0\n",
    "        elif u[j] <= p + fpr:\n",
    "            X[j] = 1.0\n",
    "            Xhat[j] = 1.0\n",
    "\n",
    "    eps = np.random.randn(N)\n",
    "    Y   = β0 + β1*X + (σ1*X + σ0*(1.0 - X))*eps\n",
    "\n",
    "    # split into train vs test\n",
    "    train_Y   = Y[:n]\n",
    "    test_Y    = Y[n:]\n",
    "\n",
    "    train_X   = Xhat[:n].reshape(-1, 1)\n",
    "    test_Xhat = Xhat[n:].reshape(-1, 1)\n",
    "    test_X    = X[n:].reshape(-1, 1)\n",
    "\n",
    "    return (train_Y, train_X), (test_Y, test_Xhat, test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-correction stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 100/1000 sims\n",
      "Done 200/1000 sims\n",
      "Done 300/1000 sims\n",
      "Done 400/1000 sims\n",
      "Done 500/1000 sims\n",
      "Done 600/1000 sims\n",
      "Done 700/1000 sims\n",
      "Done 800/1000 sims\n",
      "Done 900/1000 sims\n",
      "Done 1000/1000 sims\n"
     ]
    }
   ],
   "source": [
    "def update_results(B, S, b, V, i, method_idx):\n",
    "    \"\"\"\n",
    "    Store coefficient estimates and their SEs into B and S.\n",
    "    B,S have shape (nsim, nmethods, max_n_coefs).\n",
    "    b is length d <= max_n_coefs.  V is d×d.\n",
    "    \"\"\"\n",
    "    d = b.shape[0]\n",
    "    for j in range(d):\n",
    "        B[i, method_idx, j] = b[j]\n",
    "        S[i, method_idx, j] = np.sqrt(max(V[j, j], 0.0))\n",
    "\n",
    "for i in range(nsim):\n",
    "    (tY, tX), (eY, eXhat, eX) = generate_data(\n",
    "        n, m, p, fpr, β0, β1, σ0, σ1\n",
    "    )\n",
    "\n",
    "    # 1) OLS on unlabeled (Xhat)\n",
    "    res = ols(Y = tY, X = tX, intercept = True)\n",
    "    update_results(B, S, res.coef, res.vcov, i, 0)\n",
    "\n",
    "    # 2) OLS on labeled (true X)\n",
    "    res = ols(Y = eY, X = eX, intercept = True)\n",
    "    update_results(B, S, res.coef, res.vcov, i, 1)\n",
    "\n",
    "    # 3–8) Additive & multiplicative bias corrections\n",
    "    fpr_hat = np.mean(eXhat[:,0] * (1.0 - eX[:,0]))\n",
    "    for j in range(3):\n",
    "        fpr_bayes = (fpr_hat*m + α[j]) / (m + α[j] + β[j])\n",
    "        res = ols_bca(Y = tY, Xhat =  tX, fpr = fpr_bayes, m = m)\n",
    "        update_results(B, S, res.coef, res.vcov, i, 2 + j)\n",
    "        res = ols_bcm(Y = tY, Xhat = tX, fpr = fpr_bayes,m = m)\n",
    "        update_results(B, S, res.coef, res.vcov, i, 5 + j)\n",
    "\n",
    "    # 9) One‐step unlabeled‐only\n",
    "    res = one_step(Y = tY, Xhat = tX)\n",
    "    update_results(B, S, res.coef, res.vcov, i, 8)\n",
    "\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f\"Done {i+1}/{nsim} sims\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Coverage Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage(bgrid, b, se):\n",
    "    \"\"\"\n",
    "    Computes the coverage probability for a grid of β values.\n",
    "\n",
    "    For each value in bgrid, it computes the fraction of estimates b that\n",
    "    lie within 1.96*se of that value.\n",
    "    \"\"\"\n",
    "    cvg = np.empty_like(bgrid)\n",
    "    for i, val in enumerate(bgrid):\n",
    "        cvg[i] = np.mean(np.abs(b - val) <= 1.96 * se)\n",
    "    return cvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OLS θ̂    0.000\n",
       "OLS θ     0.937\n",
       "BCA‑0     0.884\n",
       "BCA‑1     0.919\n",
       "BCA‑2     0.918\n",
       "BCM‑0     0.883\n",
       "BCM‑1     0.898\n",
       "BCM‑2     0.899\n",
       "OSU       0.958\n",
       "Name: Coverage @ β₁=1.0, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_beta1 = 1.0\n",
    "\n",
    "methods = {\n",
    "    \"OLS θ̂\":  0,\n",
    "    \"OLS θ\": 1,\n",
    "    \"BCA‑0\": 2,\n",
    "    \"BCA‑1\": 3,\n",
    "    \"BCA‑2\": 4,\n",
    "    \"BCM‑0\": 5,\n",
    "    \"BCM‑1\": 6,\n",
    "    \"BCM‑2\": 7,\n",
    "    \"OSU\":    8,\n",
    "}\n",
    "\n",
    "cov_dict = {}\n",
    "for name, col in methods.items():\n",
    "    slopes = B[:, col, 1]\n",
    "    ses   = S[:, col, 1]\n",
    "    # fraction of sims whose 95% CI covers true_beta1\n",
    "    cov_dict[name] = np.mean(np.abs(slopes - true_beta1) <= 1.96 * ses)\n",
    "\n",
    "cov_series = pd.Series(cov_dict, name=f\"Coverage @ β₁={true_beta1}\")\n",
    "cov_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovering Coefficients and Standard Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the dataframe B stores our coefficient results while the dataframe S stores our standard errors. We can summarize our simulation results by averaging over the columns which store the results for the different simulation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Est(Beta0) SE(Beta0)    95% CI (Beta0) Est(Beta1) SE(Beta1)  \\\n",
      "Method                                                                  \n",
      "OLS (θ̂)      10.008     0.003  [10.003, 10.013]      0.833     0.021   \n",
      "OLS (θ)       10.001     0.010   [9.982, 10.020]      1.000     0.071   \n",
      "BCA (j=0)     10.002     0.004   [9.994, 10.008]      0.971     0.062   \n",
      "BCA (j=1)     10.001     0.004   [9.994, 10.008]      0.979     0.064   \n",
      "BCA (j=2)     10.001     0.004   [9.994, 10.008]      0.979     0.064   \n",
      "BCM (j=0)     10.000     0.004   [9.990, 10.008]      1.004     0.064   \n",
      "BCM (j=1)      9.999     0.004   [9.989, 10.007]      1.016     0.067   \n",
      "BCM (j=2)      9.999     0.004   [9.989, 10.007]      1.016     0.067   \n",
      "1-Step        10.000     0.003   [9.995, 10.005]      0.997     0.031   \n",
      "\n",
      "           95% CI (Beta1)  \n",
      "Method                     \n",
      "OLS (θ̂)   [0.792, 0.873]  \n",
      "OLS (θ)    [0.856, 1.141]  \n",
      "BCA (j=0)  [0.869, 1.091]  \n",
      "BCA (j=1)  [0.877, 1.100]  \n",
      "BCA (j=2)  [0.877, 1.099]  \n",
      "BCM (j=0)  [0.873, 1.188]  \n",
      "BCM (j=1)  [0.882, 1.204]  \n",
      "BCM (j=2)  [0.882, 1.203]  \n",
      "1-Step     [0.936, 1.053]  \n"
     ]
    }
   ],
   "source": [
    "nsim, nmethods, ncoeff = B.shape\n",
    "\n",
    "method_names = [\n",
    "    \"OLS (θ̂)\",\n",
    "    \"OLS (θ)\",\n",
    "    \"BCA (j=0)\",\n",
    "    \"BCA (j=1)\",\n",
    "    \"BCA (j=2)\",\n",
    "    \"BCM (j=0)\",\n",
    "    \"BCM (j=1)\",\n",
    "    \"BCM (j=2)\",\n",
    "    \"1-Step\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(nmethods):\n",
    "    row = {\"Method\": method_names[i]}\n",
    "    \n",
    "    for j, coef in enumerate([\"Beta0\", \"Beta1\"]):\n",
    "        estimates = B[:, i, j]\n",
    "        ses = S[:, i, j]\n",
    "        mean_est = np.nanmean(estimates)\n",
    "        mean_se = np.nanmean(ses)\n",
    "        lower = np.percentile(estimates, 2.5)\n",
    "        upper = np.percentile(estimates, 97.5)\n",
    "        \n",
    "        row[f\"Est({coef})\"] = f\"{mean_est:.3f}\"\n",
    "        row[f\"SE({coef})\"] = f\"{mean_se:.3f}\"\n",
    "        row[f\"95% CI ({coef})\"] = f\"[{lower:.3f}, {upper:.3f}]\"\n",
    "    \n",
    "    results.append(row)\n",
    "\n",
    "df_results = pd.DataFrame(results).set_index(\"Method\")\n",
    "print(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
