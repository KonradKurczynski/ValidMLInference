{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Example: Bias Correction in Regression with Generated Binary Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simulation example demonstrates the use of the `ValidMLInference` package for correcting bias and performing valid inference in regression models with generated binary labels.\n",
    "\n",
    "The example is based on the simulation design in [Battaglia, Christensen, Hansen & Sacher (2024)](https://arxiv.org/abs/2402.15585). Data are generated according to the model `Y = β0 + β1 * X + (σ1 X + σ0 (1 - X)) * u`, where `u` is a standard normal random variable. Parameter values are set to match the empirical example in the paper.\n",
    "\n",
    "In the main sample, the true variable `X` is latent. A predicted label `Xhat` is generated with a false positive rate `fpr`. \n",
    "\n",
    "We also generate a smaller validation sample in which both `X` and `Xhat` are observed. This sample is used to estimate `fpr`.\n",
    "\n",
    "We generate `nsim` data sets, each with `n` observations in the main sample and `m` observations from which to estimate `fpr`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ValidMLInference import ols, ols_bca, ols_bcm, one_step\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameter values and pre-allocate storage for simulation results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsim    = 1000\n",
    "n       = 16000      # training size\n",
    "m       = 1000       # test size for estimating false positive rate\n",
    "p       = 0.05       # P(X=1)\n",
    "kappa   = 1.0        # relative strength of measurement error\n",
    "fpr     = kappa / sqrt(n)\n",
    "\n",
    "β0, β1       = 10.0, 1.0\n",
    "σ0, σ1       = 0.3, 0.5\n",
    "\n",
    "# pre­allocate storage: (sim × 4 methods × 2 coefficients)\n",
    "B = np.zeros((nsim, 4, 2))\n",
    "S = np.zeros((nsim, 4, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n, m, p, fpr, β0, β1, σ0, σ1):\n",
    "    \"\"\"\n",
    "    Generates simulated data.\n",
    "\n",
    "    Parameters:\n",
    "      n, m: Python integers (number of training and test samples)\n",
    "      p, p1: floats\n",
    "      beta0, beta1: floats\n",
    "\n",
    "    Returns:\n",
    "      A tuple: ((train_Y, train_X), (test_Xhat, test_X))\n",
    "      where train_X and test_Xhat include a constant term as the second column.\n",
    "    \"\"\"\n",
    "    N = n + m\n",
    "    X    = np.zeros(N)\n",
    "    Xhat = np.zeros(N)\n",
    "    u    = np.random.rand(N)\n",
    "\n",
    "    for j in range(N):\n",
    "        if   u[j] <= fpr:\n",
    "            X[j] = 1.0\n",
    "        elif u[j] <= 2*fpr:\n",
    "            Xhat[j] = 1.0\n",
    "        elif u[j] <= p + fpr:\n",
    "            X[j] = 1.0\n",
    "            Xhat[j] = 1.0\n",
    "\n",
    "    eps = np.random.randn(N)\n",
    "    Y   = β0 + β1*X + (σ1*X + σ0*(1.0 - X))*eps\n",
    "\n",
    "    # split into train vs test\n",
    "    train_Y   = Y[:n]\n",
    "\n",
    "    train_X   = Xhat[:n].reshape(-1, 1)\n",
    "    test_Xhat = Xhat[n:].reshape(-1, 1)\n",
    "    test_X    = X[n:].reshape(-1, 1)\n",
    "\n",
    "    return (train_Y, train_X), (test_Xhat, test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data, implement methods, and store results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 100/1000 sims\n",
      "Done 200/1000 sims\n",
      "Done 300/1000 sims\n",
      "Done 400/1000 sims\n",
      "Done 500/1000 sims\n",
      "Done 600/1000 sims\n",
      "Done 700/1000 sims\n",
      "Done 800/1000 sims\n",
      "Done 900/1000 sims\n",
      "Done 1000/1000 sims\n"
     ]
    }
   ],
   "source": [
    "def update_results(B, S, b, V, i, method_idx):\n",
    "    \"\"\"\n",
    "    Store coefficient estimates and their SEs into B and S.\n",
    "    B,S have shape (nsim, nmethods, max_n_coefs).\n",
    "    b is length d <= max_n_coefs.  V is d×d.\n",
    "    \"\"\"\n",
    "    d = b.shape[0]\n",
    "    for j in range(d):\n",
    "        B[i, method_idx, j] = b[j]\n",
    "        S[i, method_idx, j] = np.sqrt(max(V[j, j], 0.0))\n",
    "\n",
    "for i in range(nsim):\n",
    "    (tY, tX), (eXhat, eX) = generate_data(\n",
    "        n, m, p, fpr, β0, β1, σ0, σ1\n",
    "    )\n",
    "\n",
    "    # Method 1: run OLS on generated labels in the main sample (biased)\n",
    "    res = ols(Y = tY, X = tX, intercept = True)\n",
    "    update_results(B, S, res.coef, res.vcov, i, 0)\n",
    "\n",
    "    # Method 2: Additive bias correction\n",
    "    fpr_hat = np.mean(eXhat[:,0] * (1.0 - eX[:,0]))\n",
    "    res = ols_bca(Y = tY, Xhat =  tX, fpr = fpr_hat, m = m)\n",
    "    update_results(B, S, res.coef, res.vcov, i, 1)\n",
    "    \n",
    "    # Method 2: Multiplicative bias correction\n",
    "    res = ols_bcm(Y = tY, Xhat = tX, fpr = fpr_hat, m = m)\n",
    "    update_results(B, S, res.coef, res.vcov, i, 2)\n",
    "\n",
    "    # Method 4: One-step estimator\n",
    "    res = one_step(Y = tY, Xhat = tX)\n",
    "    update_results(B, S, res.coef, res.vcov, i, 3)\n",
    "\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f\"Done {i+1}/{nsim} sims\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute coverage probabilities of 95% confidence intervals for the slope coefficient across methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OLS         0.000\n",
       "ols_bca     0.885\n",
       "ols_bcm     0.879\n",
       "one_step    0.929\n",
       "Name: Coverage @ β1=1.0, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods = {\n",
    "    \"OLS     \": 0,\n",
    "    \"ols_bca \": 1,\n",
    "    \"ols_bcm \": 2,\n",
    "    \"one_step\": 3\n",
    "}\n",
    "\n",
    "cov_dict = {}\n",
    "for name, col in methods.items():\n",
    "    slopes = B[:, col, 1]\n",
    "    ses   = S[:, col, 1]\n",
    "    # fraction of sims whose 95% CI covers β1\n",
    "    cov_dict[name] = np.mean(np.abs(slopes - β1) <= 1.96 * ses)\n",
    "\n",
    "cov_series = pd.Series(cov_dict, name=f\"Coverage @ β1={β1}\")\n",
    "cov_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently, standard OLS confidence intervals for the slope coefficient have coverage of zero. Both `ols_bca` and `ols_bcm` yield confidence intervals with coverage probabilities a bit below the nominal level of 95%, but their coverage approaches 95% in larger sample sizes. Moreover, `one_step` produces confidence intervals with coverage close to 95%.\n",
    "\n",
    "Finally, we tabulate results, presenting:\n",
    "\n",
    "* the average estimate and average standard error across simulations for each method;\n",
    "* intervals containing the 2.5% and 97.5% quantiles of the estimates across simultaions for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Avg_β1 Avg_SE_β1    Quantiles_β1  Avg_β0 Avg_SE_β0      Quantiles_β0\n",
      "Method                                                                       \n",
      "OLS       0.833     0.021  [0.794, 0.875]  10.008     0.003  [10.003, 10.014]\n",
      "ols_bca   0.971     0.062  [0.874, 1.091]  10.002     0.004   [9.995, 10.008]\n",
      "ols_bcm   1.003     0.064  [0.880, 1.183]  10.000     0.004   [9.991, 10.007]\n",
      "one_step  0.999     0.031  [0.926, 1.058]  10.000     0.002   [9.995, 10.005]\n"
     ]
    }
   ],
   "source": [
    "nsim, nmethods, ncoeff = B.shape\n",
    "\n",
    "method_names = [\n",
    "    \"OLS     \",\n",
    "    \"ols_bca \",\n",
    "    \"ols_bcm \",\n",
    "    \"one_step\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(nmethods):\n",
    "    row = {\"Method\": method_names[i]}\n",
    "    \n",
    "    for j, coef in enumerate([\"β1\", \"β0\"]):\n",
    "        estimates = B[:, i, 1-j]\n",
    "        ses = S[:, i, 1-j]\n",
    "        mean_est = np.nanmean(estimates)\n",
    "        mean_se = np.nanmean(ses)\n",
    "        lower = np.percentile(estimates, 2.5)\n",
    "        upper = np.percentile(estimates, 97.5)\n",
    "        \n",
    "        row[f\"Avg_{coef}\"] = f\"{mean_est:.3f}\"\n",
    "        row[f\"Avg_SE_{coef}\"] = f\"{mean_se:.3f}\"\n",
    "        row[f\"Quantiles_{coef}\"] = f\"[{lower:.3f}, {upper:.3f}]\"\n",
    "    \n",
    "    results.append(row)\n",
    "\n",
    "df_results = pd.DataFrame(results).set_index(\"Method\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that OLS estimator of the slope coefficient is biased (it under-estimates the true effect size by about 17% on average), while `ols_bca`, `ols_bcm`, and `one_step` yield estimates close to the true value of the slope coefficient. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
